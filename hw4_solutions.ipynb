{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPSCI 389: Homework 4 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Multiple Choice and Short Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. [15 points] True or False: Overfitting occurs when a parametric model is trained so much that it achieves low error on the **testing** set, but will have high error when applied to new points.\n",
    "\n",
    "***Answer***\n",
    "\n",
    "<font color=\"blue\">False.</font>\n",
    "\n",
    "---\n",
    "\n",
    "***Updated Answer***\n",
    "\n",
    "<font color=\"Green\">Using the course notes and other online materials as needed, explain why the claim is false (notice that it mentions low error on the testing set, not low error on the training set) and write one or two sentences that correctly describe overfitting.</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. [15 points] When using an artificial neural network for a classification problem with $m>2$ classes, how many outputs does the network typically have? Why?\n",
    "\n",
    "***Answer***\n",
    "\n",
    "<font color=\"blue\">\n",
    "\n",
    "The network will typically have $m$ outputs. This results in one output for each possible class (label), and making that output larger increases the probability of that class being predicted.\n",
    "\n",
    "</font>\n",
    "\n",
    "---\n",
    "\n",
    "***Updated Answer***\n",
    "\n",
    "<font color=\"Green\">\n",
    "\n",
    "Your answer should state $m$, and point out that this is the same number of outputs as there are possible classes. If not, place an updated answer in the green text. If your answer was correct, you do not need to provide an updated answer to this question.\n",
    "\n",
    "</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. [15 points] Why do we often view classifiers as stochastic (producing a probability of each label given an input) rather than deterministic during training?\n",
    "\n",
    "***Answer***\n",
    "\n",
    "<font color=\"blue\">\n",
    "\n",
    "If the classifier were to be deterministic, it would typically make the gradient of the loss function zero, making gradient descent ineffective. For example, if the predicted label corresponded to the maximum of $m$ outputs, notice that the derivative of the maximum operator would be zero except for when there is a tie between two outputs. Put differently, small changes to the weights might change the values of the outputs, but not enough to change which label is predicted for any points in the training data. If the labels don't change, the loss doesn't change, and hence the derivative of the loss with respect to the weights is zero.\n",
    "\n",
    "</font>\n",
    "\n",
    "---\n",
    "\n",
    "***Updated Answer***\n",
    "\n",
    "<font color=\"Green\">Comment on anything that your answer missed. If your answer was correct, you do not need additional reflection.</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. [15 points] For binary classification tasks, parametric models with a single output can be used. Explain how one output can be enough to select between two labels.\n",
    "\n",
    "***Answer***\n",
    "\n",
    "<font color=\"blue\">If there are only two labels, we can convert the model's single output to a probability - the probability of the positive class. The probability of the negative class can then be inferred from this value, since the probability of the negative class must be one minus the probability of the positive class.</font>\n",
    "\n",
    "---\n",
    "\n",
    "***Updated Answer***\n",
    "\n",
    "<font color=\"Green\">If your answer was correct, you do not need to provide additional reflection. If your answer was incorrect, restate the solution in your own words.</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. [15 points] The Cross-Entropy Loss is $\\operatorname{Loss}(w,D)=-\\frac{1}{n}\\sum_{i=1}^n \\ln\\left ( \\Pr(Y_i = \\hat Y_i) \\right )$. Explain this loss in English, conveying to someone learning about cross-entropy loss why they should expect that minimizing it will result in a model that makes good predictions.\n",
    "\n",
    "***Answer***\n",
    "\n",
    "<font color=\"blue\">\n",
    "\n",
    "The loss function computes minus one times the average natural logarithm of the probability that the model selects the correct label. The $-1$ factor can be viewed as flipping the minimization to a maximization of the remaining loss: $\\frac{1}{n}\\sum_{i=1}^n \\ln\\left ( \\Pr(Y_i = \\hat Y_i) \\right )$. Without the natural logarithm, this is the average probability that the model selects the right label, and so maximizing this maximizes the average probability that the model makes the right prediction. The natural logarithm is a monotonic function, so it does not change the intuitive meaning, but rather rescales how different probabilities contribute to the loss. Specifically, the natural logarithm makes it so that changing the probability of the correct label from $0.5$ to $0.6$ has a bigger impact than changing it from $0.8$ to $0.9$. \n",
    "\n",
    "</font>\n",
    "\n",
    "---\n",
    "\n",
    "***Updated Answer***\n",
    "\n",
    "<font color=\"Green\">Your answer need not delve into the details of the natural logarithm. Describe any other aspects of the answer above that you did not cover. If your answer was correct, you do not need to provide an additional response.</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. [15 points] Give an example where a parametric model with $99\\%$ accuracy corresponds to a model with *poor* performance.\n",
    "\n",
    "***Initial Answer***\n",
    "\n",
    "<font color=\"blue\">\n",
    "\n",
    "There are many possible answers. Here is one:\n",
    "\n",
    "When predicting whether a rock is a meteorite, if $99.9\\%$ are *not* meteorites, then a classifier that always predicts \"not a meteorite\" will have $99.9\\%$ accuracy, and so an accuracy of $99\\%$ would be worse than this naive classifier. The key issue is that the interpretation of accuracy depends on the proportions of the different class labels.\n",
    "\n",
    "</font>\n",
    "\n",
    "---\n",
    "\n",
    "***Updated Answer***\n",
    "\n",
    "<font color=\"Green\">If your answer was not correct or complete, provide a reworded solution in your updated answer. If your answer was correct, you do not need to provide an additional response.</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. [15 points] You are tasked with making an ML system for predicting whether a tumor is benign or malignant. If the tumor is predicted to be benign, the patient will be sent away and checked again in another few years. If the tumor is malignant, a human doctor will look at the results and determine how to proceed. Propose a loss function for this task and explain why it would be appropriate.\n",
    "\n",
    "***Answer***\n",
    "\n",
    "<font color=\"blue\">\n",
    "\n",
    "Predicting \"benign\" when the tumor is malignant is particularly bad, since it will result in someone not receiving proper treatment. Predicting \"malignant\" when the tumor is benign will waste some human time - having a doctor review the case - but will not result in significant harm. So, a false negative is far worse than a false positive. We could therefore define a loss function like the following, where benign corresponds to the label 0 and malignant to 1:\n",
    "\n",
    "$$\n",
    "L(w,D)=\\frac{1}{n}\\sum_{i=1}^n \n",
    "    \\begin{cases}\n",
    "        w_1 \\Pr(\\hat Y_i = 0) & \\text{ if } Y_i = 1\\\\\n",
    "        w_2 \\Pr(\\hat Y_i = 1) & \\text{ if } Y_i = 0,\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "where $w_1>0$ and $w_2>0$ are different weights. By making $w_1$ much larger than $w_2$, we encourage the model to avoid false negatives (when $\\hat Y_i=0$ even though $Y_i=1$), even at the cost of several false positives. This is merely one example of a possible answer. The key points are that the loss function should penalize false negatives the most, and that it should not *only* penalize false negatives.\n",
    "\n",
    "</font>\n",
    "\n",
    "---\n",
    "\n",
    "***Updated Answer***\n",
    "\n",
    "<font color=\"Green\">\n",
    "\n",
    "Update your answer if you believe any of your answer was not correct. **Regardless of whether your initial answer was correct**, explain why a loss function that only penalizes false negatives (with no loss incurred for any other correct or incorrect answer) would result in an undesirable model. That is, explain why the loss above with $w_2=0$ and $w_1 > 0$ is not effective.\n",
    "\n",
    "</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. [15 points] Can the accuracy of a model be computed from the confusion matrix? If no, why not, and if yes, how?\n",
    "\n",
    "Note: For simplicity, assume the confusion matrix reports the number of samples falling into each category, not the probability.\n",
    "\n",
    "***Initial Answer***\n",
    "\n",
    "<font color=\"blue\">\n",
    "\n",
    "Yes. The diagonal of the confusion matrix contains the samples where the label was correctly predicted, and off-diagonal entries contain the samples where the label was not correctly predicted. Hence, the sum of the values on the diagonal divided by the sum of all entries in the matrix is equal to the number of correctly labeled points divided by the total number of points, which is the accuracy.\n",
    "\n",
    "</font>\n",
    "\n",
    "---\n",
    "\n",
    "***Updated Answer***\n",
    "\n",
    "<font color=\"Green\"> Ensure that your answer was correct. Notice that the denominator is the total number of points, not the sum of the off-diagonal points. If your answer was not correct, provide a correct answer in your own words. If your answer was correct, you do not need to provide an additional response.</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. [15 points] What are the two main components of a VAE, and what does each do?\n",
    "\n",
    "Note: We are looking for one sentence per component.\n",
    "\n",
    "***Answer***\n",
    "\n",
    "<font color=\"blue\">\n",
    "\n",
    "**Encoder**: The encoder converts the input (e.g., an image) into a vector in the latent space.\n",
    "\n",
    "**Decoder**: The decoder converts a vector in the latent space into a synthetic (fake) data point (e.g., an image).\n",
    "\n",
    "</font>\n",
    "\n",
    "---\n",
    "\n",
    "***Updated Answer***\n",
    "\n",
    "<font color=\"Green\">\n",
    "If your answer was incorrect, provide an updated and correct answer. If your answer was correct, you do not need to provide an additional response.\n",
    "</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. [15 points] What are the two main components of a GAN, and what does each do?\n",
    "\n",
    "Note: We are looking for one sentence per component.\n",
    "\n",
    "***Answer***\n",
    "\n",
    "<font color=\"blue\">\n",
    "\n",
    "**Generator**: The generator takes noise as input and produces as output a synthetic data point (e.g., an image).\n",
    "\n",
    "**Discriminator**: The discriminator takes a data point (e.g., an image) as input and predicts whether the image is a real image from the training data or a synthetic image created by the generator.\n",
    "\n",
    "</font>\n",
    "\n",
    "---\n",
    "\n",
    "***Updated Answer***\n",
    "\n",
    "<font color=\"Green\">\n",
    "If your answer was incorrect, provide an updated and correct answer. If your answer was correct, you do not need to provide an additional response.\n",
    "</font>\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. [15 points] We described how VAEs include a term in the loss function that encourages the latent representation of the training data to be normally distributed in the latent space. What tends to go wrong when this term is omitted?\n",
    "\n",
    "***Initial Answer***\n",
    "\n",
    "<font color=\"blue\">\n",
    "\n",
    "If this term is omitted, then all of the images in the training data might map to a small portion of the latent space. When generating new images, the randomly sampled noise vector might fall in part of the latent space where the decoder has no experience recreating inputs. So, even though the decoder could be effective at converting latent representations of the training data back to inputs (e.g., images), it may not be effective at converting random vectors in the latent space back to inputs (e.g., images).\n",
    "\n",
    "</font>\n",
    "\n",
    "---\n",
    "\n",
    "***Updated Answer***\n",
    "\n",
    "<font color=\"Green\">\n",
    "If your answer was incorrect, provide an updated and correct answer. If your answer was correct, you do not need to provide an additional response.\n",
    "</font>\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}